{
  "hash": "19a67f408cd5843ede693adecbad4ec6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Week 8 practice\nformat: live-html\nengine: knitr\nwebr:\n  packages:\n    - wordcloud\n    - tm\n---\n\n## Text analytics\n\n::: {.cell}\n\n:::\n\n\n\nIn **Week 8 Workshop** we are using text analytics and classification models to predict whether YouTube comments are HAM or SPAM.\n\n## What is random?\n\nA very simple way of analysing text is to count occurances of words.\nWe see word clouds a lot!\nHow useful are they?\n\n::: {.callout-tip title=\"Load in your 'corpus' or document\" collapse=\"true\"}\n\n::: {.cell}\n```{webr}\ntext <- c(\"Summative Assessment: Assignment 1 Deadline: \n14 March 2025 Time: 15:00 hours\nMaterials Provided. \n\nIn this assignment, you will apply and evaluate a random forest model to a \ndataset containing information from a mailing campaign. Your task is to \ndevelop a classification model to identify individuals most likely to donate \nto the campaign, based on the features provided in the data. You will assess \nthe model's performance, evaluate its fit, and analyse how different features \ncontribute to its predictive accuracy.\n\n    You will be provided with a video stepping through a random forest in R, \n    which is applied to a different dataset.\n    You will be provided with the mailing campaign dataset and an RMarkdown \n    file to work with and adapt the code provided in the video.\n\nObjectives\nOn completion of this assessment, you will:\n\n    Derive and evaluate information toward a specific challenge\n    Use data visualisation to share content and insight\n    Interpret and understand the potential implications of your analysis\n\nInstructions\n\n    Log into ELE, navigate to the Assessments tile. \n    Watch the Summative Assessment video\n    Download the folder containing your data and RMarkdown file.\n    Recreate the code from the video using your own dataset. I encourage you \n    to work in groups of 2-3 for this if you are inexperienced with coding.  \n    Ideally, you need to get all of the code running.\n    Spend some time interpreting the outputs of your code.\n    Interpret and consider the possible implications of the outcomes.  Your \n    analysis needs to be individual work.\n    Complete the RMarkdown file with your individual interpretations, and knit \n    it to pdf and/or html to produce a fully rendered report. You will submit \n    a single rendered report via ELE.\n\nAdvice for success\n\n    Participate actively in all workshop sessions, and try to understand what \n    the code is doing and why. Attend lectures, engage with materials on ELE.\n    Work effectively with your peers to debug and troubleshoot code\n    Ensure your rendered report is clear, organised, and proof-read.\n    Talk to the module convenor if you feel stuck.\")\n```\n:::\n\n:::\n\n\n::: {.cell}\n```{webr}\n# Create a text corpus\ncorpus <- Corpus(VectorSource(text))\n\n# Preprocess the text: remove punctuation, numbers, whitespace, and convert to lowercase\ncorpus <- tm_map(corpus, content_transformer(tolower))\ncorpus <- tm_map(corpus, removePunctuation)\ncorpus <- tm_map(corpus, removeNumbers)\ncorpus <- tm_map(corpus, stripWhitespace)\n\n# Create a term-document matrix\ntdm <- TermDocumentMatrix(corpus)\n\n# Convert the matrix to a data frame\nm <- as.matrix(tdm)\nword_freqs <- sort(rowSums(m), decreasing = TRUE) \ndf <- data.frame(word = names(word_freqs), freq = word_freqs)\n\n# Plot the word cloud\nwordcloud(words = df$word, freq = df$freq, min.freq = 1,\n          max.words=200, random.order=FALSE, rot.per=0.35, \n          colors=brewer.pal(8, \"Dark2\"),\n          scale = c(7,0.5))\n\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}